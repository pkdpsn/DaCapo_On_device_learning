{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-05T12:43:53.676874Z",
     "start_time": "2024-11-05T12:43:53.672377Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T12:44:04.503488Z",
     "start_time": "2024-11-05T12:44:04.496665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import torch.nn as nn\n",
    "# from model20C_2F import MNIST_CNN\n",
    "# # Device configuration\n",
    "# device = 'cpu'  # 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# \n",
    "# def compute_cost(layer, input_shape):\n",
    "#     \"\"\"\n",
    "#     Compute the computation cost C_i for a given layer.\n",
    "#     \n",
    "#     Parameters:\n",
    "#     - layer: The layer to compute the cost for.\n",
    "#     - input_shape: Tuple representing the shape (batch_size, channels, height, width) for conv layers,\n",
    "#                    (batch_size, features) for dense layers.\n",
    "#     \n",
    "#     Returns:\n",
    "#     - cost: Computation cost C_i for the layer.\n",
    "#     \"\"\"\n",
    "#     if isinstance(layer, nn.Conv2d):\n",
    "#         # Conv2D layers\n",
    "#         output_channels = layer.out_channels\n",
    "#         input_channels = layer.in_channels\n",
    "#         kernel_height, kernel_width = layer.kernel_size\n",
    "#         \n",
    "#         # Assuming stride=1 and padding keeps input and output size the same\n",
    "#         output_height, output_width = input_shape[2], input_shape[3]\n",
    "#         print(\"Conv2d layer:\", output_channels, kernel_height, kernel_width)\n",
    "#         # Calculate cost for convolutional layer\n",
    "#         cost = (output_height * output_width * output_channels *\n",
    "#                 kernel_height * kernel_width * input_channels)\n",
    "#     \n",
    "#     elif isinstance(layer, nn.Linear):\n",
    "#         # Dense (Fully Connected) layers\n",
    "#         print(\"Dense\", layer.in_features, layer.out_features)\n",
    "#         input_features = layer.in_features\n",
    "#         output_features = layer.out_features\n",
    "#         \n",
    "#         # Calculate cost for dense layer\n",
    "#         cost = input_features * output_features\n",
    "# \n",
    "#     else:\n",
    "#         # No cost for other layers like ReLU or Flatten\n",
    "#         cost = 0\n",
    "#     print(f\"Computation Cost:\", cost)\n",
    "#     return cost\n",
    "# \n",
    "# # Function to calculate total cost for the entire model\n",
    "# def compute_total_cost(model, input_shape):\n",
    "#     total_cost = 0\n",
    "#     for layer in model.children():\n",
    "#         if isinstance(layer, nn.Sequential):\n",
    "#             for sublayer in layer:\n",
    "#                 input_shape = (input_shape[0], layer[0].out_channels, input_shape[2], input_shape[3]) # Update input shape\n",
    "#                 layer_cost = compute_cost(sublayer, input_shape)\n",
    "#                 total_cost += layer_cost\n",
    "#         else:\n",
    "#             layer_cost = compute_cost(layer, input_shape)\n",
    "#             total_cost += layer_cost\n",
    "#             if isinstance(layer, nn.Linear):\n",
    "#                 input_shape = (input_shape[0], layer.out_features)  # Update for next layer if dense layer\n",
    "# \n",
    "#     return total_cost\n",
    "# \n",
    "# # Initialize model and compute total cost\n",
    "# input_shape = (1, 1, 28, 28)  # Example input shape (batch_size=1, channels=1, height=28, width=28)\n",
    "# model = MNIST_CNN(input_shape=1, hidden_units=10, output_shape=10).to(device)\n",
    "# total_cost = compute_total_cost(model, input_shape)\n",
    "# \n",
    "# print(\"Total Computation Cost:\", total_cost)\n"
   ],
   "id": "f00eaa207156b685",
   "outputs": [],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T10:59:36.866848Z",
     "start_time": "2024-11-05T10:59:36.854601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "from model20C_2F import MNIST_CNN\n",
    "device = 'cpu'  \n",
    "\n",
    "layer_map = {\n",
    "    **{i: {\"type\": \"conv\", \"in_channels\": 10, \"out_channels\": 10, \"kernel_size\": 3, \"height\": 28, \"width\": 28} for i in range(1, 21)},\n",
    "    21: {\"type\": \"dense\", \"in_features\": 10 * 28 * 28, \"out_features\": 10},\n",
    "    22: {\"type\": \"dense\", \"in_features\": 10, \"out_features\": 10}\n",
    "}\n",
    "\n",
    "def layer_memory_req(layer_info):\n",
    "    \"\"\"\n",
    "    Calculate memory requirement for a single layer based on its type and parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    - layer_info: Dictionary containing layer type and parameters.\n",
    "    \n",
    "    Returns:\n",
    "    - memory_req: Memory requirement for the layer in bytes (or any unit).\n",
    "    \"\"\"\n",
    "    if layer_info[\"type\"] == \"conv\":\n",
    "        in_channels = layer_info[\"in_channels\"]\n",
    "        out_channels = layer_info[\"out_channels\"]\n",
    "        kernel_size = layer_info[\"kernel_size\"]\n",
    "        height = layer_info[\"height\"]\n",
    "        width = layer_info[\"width\"]\n",
    "        \n",
    "        # Memory required for activations (output size) + parameters (weights)\n",
    "        activations_mem = height * width * out_channels * 4  # 4 bytes per float\n",
    "        weights_mem = (kernel_size * kernel_size * in_channels * out_channels) * 4\n",
    "        memory_req = activations_mem + weights_mem\n",
    "        \n",
    "\n",
    "    elif layer_info[\"type\"] == \"dense\":\n",
    "        in_features = layer_info[\"in_features\"]\n",
    "        out_features = layer_info[\"out_features\"]\n",
    "        \n",
    "        # Memory for activations (output size) + parameters (weights)\n",
    "        activations_mem = out_features * 4  # 4 bytes per float\n",
    "        weights_mem = in_features * out_features * 4\n",
    "        memory_req = activations_mem + weights_mem\n",
    "\n",
    "    else:\n",
    "        memory_req = 0  # For non-trainable or unsupported layer types\n",
    "\n",
    "    return memory_req/1024\n",
    "\n",
    "def max_segment_mem_req(segment):\n",
    "    \"\"\"\n",
    "    Calculate the maximum memory requirement for a given segment of layers.\n",
    "    \n",
    "    Parameters:\n",
    "    - segment: List of layer indices representing a segment of the model (e.g., [1, 3, 7, 12]).\n",
    "    \n",
    "    Returns:\n",
    "    - max_memory: Maximum memory requirement within the segment.\n",
    "    \"\"\"\n",
    "    max_memory = 0\n",
    "    \n",
    "    for layer_index in segment:\n",
    "        layer_info = layer_map.get(layer_index, None)\n",
    "        if layer_info is not None:\n",
    "            layer_memory = layer_memory_req(layer_info)\n",
    "            print(layer_memory)\n",
    "            max_memory = max(max_memory, layer_memory)\n",
    "        else:\n",
    "            print(f\"Warning: Layer {layer_index} not found in layer map.\")\n",
    "\n",
    "    return max_memory\n",
    "`\n",
    "# Example Usage\n",
    "segment = [1, 2, 7,12, 21 ,22]\n",
    "max_memory = max_segment_mem_req(segment)\n",
    "print(\"Maximum Memory Requirement for Segment:\", max_memory)\n"
   ],
   "id": "d59bf24f612ee376",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.140625\n",
      "34.140625\n",
      "34.140625\n",
      "34.140625\n",
      "306.2890625\n",
      "0.4296875\n",
      "Maximum Memory Requirement for Segment: 306.2890625\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch import mm\n",
    "device = 'cpu'\n",
    "\n",
    "layer_map = {\n",
    "    **{i: {\"type\": \"conv\", \"in_channels\": 10, \"out_channels\": 10, \"kernel_size\": 3, \"height\": 28, \"width\": 28} for i in range(1, 21)},\n",
    "    21: {\"type\": \"dense\", \"in_features\": 10 * 28 * 28, \"out_features\": 10},\n",
    "    22: {\"type\": \"dense\", \"in_features\": 10, \"out_features\": 10}\n",
    "}\n",
    "\n",
    "## compute and store all Ci \n"
   ],
   "id": "3a5f160b71b0baf8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T12:49:28.239421Z",
     "start_time": "2024-11-05T12:49:28.226406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "from model5C_2F import MNIST_CNN\n",
    "\n",
    "# Device configuration\n",
    "device = 'cpu'  # 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def compute_cost(layer, input_shape):\n",
    "    \"\"\"\n",
    "    Compute the computation cost C_i for a given layer.\n",
    "    \n",
    "    Parameters:\n",
    "    - layer: The layer to compute the cost for.\n",
    "    - input_shape: Tuple representing the shape (batch_size, channels, height, width) for conv layers,\n",
    "                   (batch_size, features) for dense layers.\n",
    "    \n",
    "    Returns:\n",
    "    - cost: Computation cost C_i for the layer.\n",
    "    \"\"\"\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        output_channels = layer.out_channels\n",
    "        input_channels = layer.in_channels\n",
    "        kernel_height, kernel_width = layer.kernel_size\n",
    "        output_height, output_width = input_shape[2], input_shape[3]\n",
    "        \n",
    "        cost = (output_height * output_width * output_channels *\n",
    "                kernel_height * kernel_width * input_channels)\n",
    "    \n",
    "    elif isinstance(layer, nn.Linear):\n",
    "        input_features = layer.in_features\n",
    "        output_features = layer.out_features\n",
    "        cost = input_features * output_features\n",
    "    else:\n",
    "        cost = 0\n",
    "    return cost\n",
    "\n",
    "def compute_layer_costs(model, input_shape):\n",
    "    \"\"\"\n",
    "    Compute and return the computation cost C_i for each layer in the model.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The neural network model.\n",
    "    - input_shape: The input shape for the model.\n",
    "    \n",
    "    Returns:\n",
    "    - layer_costs: A list of tuples, each containing the layer name and its computation cost.\n",
    "    \"\"\"\n",
    "    layer_costs = []\n",
    "    layer_num = 1  # Start layer numbering at 1\n",
    "    \n",
    "    for layer in model.children():\n",
    "        if isinstance(layer, nn.Sequential):\n",
    "            for sublayer in layer:\n",
    "                input_shape = (input_shape[0], layer[0].out_channels, input_shape[2], input_shape[3])  # Update input shape\n",
    "                layer_cost = compute_cost(sublayer, input_shape)\n",
    "                if layer_cost == 0:\n",
    "                    continue\n",
    "                layer_costs.append(layer_cost)\n",
    "                layer_num += 1\n",
    "        else:\n",
    "            layer_cost = compute_cost(layer, input_shape)\n",
    "            if layer_cost == 0:\n",
    "                continue\n",
    "            layer_costs.append( layer_cost)\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                input_shape = (input_shape[0], layer.out_features)  # Update for next layer if dense layer\n",
    "            layer_num += 1\n",
    "\n",
    "    return layer_costs\n",
    "\n",
    "# Initialize model and compute layer costs\n",
    "input_shape = (1, 1, 28, 28)  # Example input shape (batch_size=1, channels=1, height=28, width=28)\n",
    "model = MNIST_CNN(input_shape=1, hidden_units=10, output_shape=10).to(device)\n",
    "layer_costs = compute_layer_costs(model, input_shape)\n",
    "\n",
    "# Print the list of all Ci values\n",
    "print(\"List of all Ci values (computation costs for each layer):\")\n",
    "i =0\n",
    "for  cost in layer_costs:\n",
    "    print(f\"Layer{i}: Computation Cost = {cost}\")\n",
    "    i+=1\n"
   ],
   "id": "415e6577447afa5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all Ci values (computation costs for each layer):\n",
      "Layer0: Computation Cost = 70560\n",
      "Layer1: Computation Cost = 705600\n",
      "Layer2: Computation Cost = 705600\n",
      "Layer3: Computation Cost = 705600\n",
      "Layer4: Computation Cost = 705600\n",
      "Layer5: Computation Cost = 78400\n",
      "Layer6: Computation Cost = 100\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T12:49:30.862985Z",
     "start_time": "2024-11-05T12:49:30.846095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "from model5C_2F import MNIST_CNN\n",
    "\n",
    "# Device configuration\n",
    "device = 'cpu'  # 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def layer_memory_req(layer, input_shape):\n",
    "    \"\"\"\n",
    "    Calculate memory requirement for a single layer based on its type and parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    - layer: The layer object (either Conv2d or Linear).\n",
    "    - input_shape: Tuple representing the shape (batch_size, channels, height, width) for conv layers,\n",
    "                   (batch_size, features) for dense layers.\n",
    "    \n",
    "    Returns:\n",
    "    - memory_req_kb: Memory requirement for the layer in kilobytes (KB).\n",
    "    \"\"\"\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        # Conv2D layer parameters\n",
    "        out_channels = layer.out_channels\n",
    "        kernel_size = layer.kernel_size[0]\n",
    "        in_channels = layer.in_channels\n",
    "        output_height, output_width = input_shape[2], input_shape[3]\n",
    "\n",
    "        # Memory for activations (output size) + parameters (weights)\n",
    "        activations_mem = output_height * output_width * out_channels * 4  # 4 bytes per float\n",
    "        weights_mem = (kernel_size * kernel_size * in_channels * out_channels) * 4  # Weights\n",
    "        memory_req = activations_mem + weights_mem\n",
    "\n",
    "    elif isinstance(layer, nn.Linear):\n",
    "        # Linear layer parameters\n",
    "        in_features = layer.in_features\n",
    "        out_features = layer.out_features\n",
    "\n",
    "        # Memory for activations (output size) + parameters (weights)\n",
    "        activations_mem = out_features * 4  # 4 bytes per float\n",
    "        weights_mem = in_features * out_features * 4  # Weights\n",
    "        memory_req = activations_mem + weights_mem\n",
    "\n",
    "    else:\n",
    "        memory_req = 0  # Unsupported layer types\n",
    "\n",
    "    # Convert bytes to kilobytes\n",
    "    memory_req_kb = memory_req / 1024\n",
    "    return memory_req_kb\n",
    "\n",
    "def layer_memory_list(model, input_shape):\n",
    "    \"\"\"\n",
    "    Calculate the memory requirement for each layer in the model and return a list.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The neural network model.\n",
    "    - input_shape: The input shape for the model.\n",
    "    \n",
    "    Returns:\n",
    "    - layer_memory_list: List of memory requirements for each layer in kilobytes (KB).\n",
    "    \"\"\"\n",
    "    layer_memory_list = []\n",
    "    layer_num = 1  # Start layer numbering at 1\n",
    "    \n",
    "    # Iterate over the model layers\n",
    "    for layer in model.children():\n",
    "        if isinstance(layer, nn.Sequential):\n",
    "            for sublayer in layer:\n",
    "                layer_memory = layer_memory_req(sublayer, input_shape)\n",
    "                if layer_memory != 0:\n",
    "                    layer_memory_list.append( layer_memory)\n",
    "                    # print(f\"Layer {layer_num}: Memory Requirement = {layer_memory} KB\")\n",
    "                    layer_num += 1\n",
    "        else:\n",
    "            layer_memory = layer_memory_req(layer, input_shape)\n",
    "            if layer_memory != 0:\n",
    "                layer_memory_list.append( layer_memory/4)\n",
    "                # print(f\"Layer {layer_num}: Memory Requirement = {layer_memory} KB\")\n",
    "                layer_num += 1\n",
    "\n",
    "    return layer_memory_list\n",
    "\n",
    "# Initialize model\n",
    "input_shape = (1, 1, 28, 28)  # Example input shape (batch_size=1, channels=1, height=28, width=28)\n",
    "model = MNIST_CNN(input_shape=1, hidden_units=10, output_shape=10).to(device)\n",
    "\n",
    "# Get memory requirements for each layer\n",
    "layer_memory = layer_memory_list(model, input_shape)\n",
    "print(\"\\nList of Memory Requirements for Each Layer (in KB):\")\n",
    "i=0\n",
    "for  memory in layer_memory:\n",
    "    print(f\"{i}: {memory} KB\")\n",
    "    i+=1\n"
   ],
   "id": "ecfd5a7464c24c2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List of Memory Requirements for Each Layer (in KB):\n",
      "0: 30.9765625 KB\n",
      "1: 34.140625 KB\n",
      "2: 34.140625 KB\n",
      "3: 34.140625 KB\n",
      "4: 34.140625 KB\n",
      "5: 76.572265625 KB\n",
      "6: 0.107421875 KB\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T12:52:55.913979Z",
     "start_time": "2024-11-05T12:52:55.904159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def Rkp(Ci, F, L):\n",
    "    \"\"\"\n",
    "    Calculate the weighted computation cost for a segment of layers.\n",
    "    \n",
    "    Parameters:\n",
    "    - Ci: List of computation costs for each layer.\n",
    "    - F: Starting index of the segment (exclusive).\n",
    "    - L: Ending index of the segment (inclusive).\n",
    "    \n",
    "    Returns:\n",
    "    - sum: Total weighted computation cost for the segment.\n",
    "    \"\"\"\n",
    "    sum = 0\n",
    "    if F == 0:\n",
    "        for i in range(F , L):\n",
    "            # print(i, i - F+1)  \n",
    "            sum += Ci[i] * (i - F+1)\n",
    "    else:\n",
    "        for i in range(F + 1, L):\n",
    "            # print(i, i - F)  \n",
    "            sum += Ci[i] * (i - F)\n",
    "    return sum\n",
    "def computation_cost(Ci, seg):\n",
    "    \"\"\"\n",
    "    Calculate the total computation cost across multiple segments of layers.\n",
    "    \n",
    "    Parameters:\n",
    "    - Ci: List of computation costs for each layer.\n",
    "    - segment: List of segment boundaries (layer indices). Each boundary marks the end of a segment.\n",
    "    \n",
    "    Returns:\n",
    "    - sum: Total computation cost across all segments.\n",
    "    \"\"\"\n",
    "    sum = 0\n",
    "    prev = 0\n",
    "    segment = seg.copy()\n",
    "    segment.append(len(Ci)-1)  # Ensure the last segment goes to the end of Ci\n",
    "\n",
    "    for i in range(len(segment)):\n",
    "        # print(prev, segment[i])  # Debug: Print segment start and end indices\n",
    "        sum += Rkp(Ci, prev, segment[i])\n",
    "        prev = segment[i]\n",
    "\n",
    "    return sum\n",
    "\n",
    "\n",
    "Rkp(layer_costs ,2,3)\n"
   ],
   "id": "615d2fc8ce7d4075",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T12:52:56.579026Z",
     "start_time": "2024-11-05T12:52:56.572991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "segment = []\n",
    "computation_cost(layer_costs,segment )"
   ],
   "id": "193b1f138bfea4a3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10419360"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T12:52:57.052798Z",
     "start_time": "2024-11-05T12:52:57.043880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def max_mem_req(Mi , curr_seg):\n",
    "    mem_sum = 0\n",
    "    for i in range(len(curr_seg)):\n",
    "        mem_sum += Mi[curr_seg[i]]\n",
    "    return mem_sum\n",
    "\n",
    "max_mem_req(layer_memory ,[2])"
   ],
   "id": "e634e39b32c95265",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.140625"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T12:52:57.523447Z",
     "start_time": "2024-11-05T12:52:57.516115Z"
    }
   },
   "cell_type": "code",
   "source": "len(layer_memory)",
   "id": "aef36ca54334b159",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T12:55:53.557157Z",
     "start_time": "2024-11-05T12:55:53.550183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def optimalSegFinder(Ci,Mi,M, n):\n",
    "    \"\"\"\n",
    "    Finds the optimal segmentation of layers with minimal computation cost, subject to memory constraints.\n",
    "    \n",
    "    Parameters:\n",
    "    - Ci: List of computation costs for each layer.\n",
    "    - M: Available memory size.\n",
    "    - n: Total number of layers.\n",
    "    \n",
    "    Returns:\n",
    "    - optimal_seg: Optimal segmentation that minimizes computation cost.\n",
    "    - min_cost: Minimum computation cost of the optimal segmentation.\n",
    "    \"\"\"\n",
    "    # Initialize variables\n",
    "    min_cost = float('inf')\n",
    "    optimal_seg = []\n",
    "    cur_seg = []\n",
    "\n",
    "    def recursive_optimal_seg_finder(cur_seg, index):\n",
    "        nonlocal min_cost, optimal_seg\n",
    "\n",
    "        # Check if the current segment meets memory requirements\n",
    "        if max_mem_req(Mi,cur_seg) <= M:\n",
    "            # Calculate the computation cost for the current segmentation\n",
    "            cost = computation_cost(Ci, cur_seg)\n",
    "            # print(f\" {cost} {cur_seg} \")\n",
    "            # Update minimum cost and optimal segmentation if a better solution is found\n",
    "            if cost < min_cost:\n",
    "                min_cost = cost\n",
    "                optimal_seg = cur_seg[:]\n",
    "        \n",
    "        # Iterate over possible next layers to add to the current segmentation\n",
    "        for i in range(index, n):\n",
    "            # Recursively find the optimal segmentation with the next layer added to cur_seg\n",
    "            # print(f\"adding {i} to curr {cur_seg}\")\n",
    "            recursive_optimal_seg_finder(cur_seg + [i], i + 1)\n",
    "\n",
    "    # Start the recursion with an empty segmentation and at the first layer\n",
    "    recursive_optimal_seg_finder(cur_seg, 1)\n",
    "\n",
    "    return optimal_seg, min_cost\n"
   ],
   "id": "a29ed9c485dcccaa",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T12:55:54.053520Z",
     "start_time": "2024-11-05T12:55:54.047555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Ci = layer_costs\n",
    "Mi = layer_memory\n",
    "M = 200\n",
    "n = len(layer_costs)-1\n",
    "optimal_seg, min_cost = optimalSegFinder(Ci,Mi ,M, n)\n",
    "print(\"Optimal Segmentation:\", optimal_seg)\n",
    "print(\"Minimum Computation Cost:\", min_cost)"
   ],
   "id": "19b1b8d77f011f91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Segmentation: [1, 2, 3, 4]\n",
      "Minimum Computation Cost: 148960\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "19146c7a5817ba7f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7bd7c387c2539f8e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
